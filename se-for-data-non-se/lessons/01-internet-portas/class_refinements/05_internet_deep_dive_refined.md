# Por Baixo dos Panos: Protocolos AvanÃ§ados e o Mundo Real

AtÃ© agora, falamos de HTTP, Portas e SeguranÃ§a â€” os blocos fundamentais. Mas o mundo real de Engenharia de Dados vive muito alÃ©m de REST APIs. Esta aula Ã© o "deep dive" nos protocolos e padrÃµes que vocÃª encontra em pipelines, clusters e aplicaÃ§Ãµes de IA modernas.

---

## ğŸ“‹ Tabela DiagnÃ³stica (vs. Fontes Originais)

| SeÃ§Ã£o | Veredicto | Detalhe |
|:------|:---------:|:--------|
| Â§1 gRPC | âœ… | Fiel Ã  doc oficial |
| Â§1 Thrift | ğŸ”µ | Adicionado: **IDL** (Interface Definition Language) em mais profundidade |
| Â§2 Spark + S3 | âœ… | Mantido â€” excelente |
| Â§3 Front/Back | âœ… | Mantido |
| Â§3 SerializaÃ§Ã£o | ğŸ”µ | Adicionado: **Protobuf vs JSON vs Avro** comparaÃ§Ã£o para DE |
| Â§4 SSE | ğŸ”µ | Adicionado: **SSE vs WebSocket** (uni vs bidirecional) |
| Â§4 Vector Search | ğŸ”µ | Atualizado com conceitos de embedding mais precisos |
| Nota de RodapÃ© | âœ… | Mantido |
| **WebSocket** | ğŸŸ¡â†’âœ… | **Adicionado** â€” explicaÃ§Ã£o bÃ¡sica |
| **REST vs gRPC vs GraphQL** | ğŸŸ¡â†’âœ… | **Adicionado** â€” tabela comparativa |
| **Checkpoint** | ğŸŸ¡â†’âœ… | **Adicionado** |
| **AplicaÃ§Ã£o Imediata** | ğŸŸ¡â†’âœ… | **Adicionado** |

---

## 1. Protocolos BinÃ¡rios: gRPC e Thrift

AtÃ© agora, tudo que vimos foi HTTP e JSON â€” texto legÃ­vel por humanos. Mas quando o volume de dados Ã© gigantesco e a latÃªncia precisa ser mÃ­nima, texto Ã© muito caro.

### Por que "binÃ¡rio" Ã© mais rÃ¡pido?

```
JSON (texto):   {"temperatura": 23.5, "sensor": "A1"}
                                         â†“
                        42 bytes, precisa parsear como string

Protobuf (binÃ¡rio): 08 97 01 12 02 41 31
                                         â†“
                        7 bytes, estrutura fixa, parse direto
```

O dado Ã© o mesmo, mas a representaÃ§Ã£o binÃ¡ria Ã© **6x menor** e **10-100x mais rÃ¡pida** de parsear.

### gRPC (Google Remote Procedure Call)

O gRPC Ã© um framework de comunicaÃ§Ã£o **cliente-servidor** criado pelo Google. Ã‰ o protocolo que conecta os microserviÃ§os internos do Google (Bigtable, Spanner, Gmail, YouTube â€” tudo se comunica via gRPC internamente).

**Componentes:**

1.  **Protocol Buffers (Protobuf):** O formato de serializaÃ§Ã£o binÃ¡ria. VocÃª define o "contrato" em um arquivo `.proto`:

```protobuf
// sensor.proto â€” o "contrato" entre cliente e servidor
syntax = "proto3";

service SensorService {
    rpc GetTemperatura (SensorRequest) returns (TemperaturaResponse);
    rpc StreamLeituras (SensorRequest) returns (stream LeituraResponse);
}

message SensorRequest {
    string sensor_id = 1;    // campo 1
    int32 ultimos_minutos = 2; // campo 2
}

message TemperaturaResponse {
    double valor = 1;
    string unidade = 2;
}
```

2.  **HTTP/2 como transporte:** O gRPC roda obrigatoriamente sobre HTTP/2 (multiplexaÃ§Ã£o de streams).
3.  **GeraÃ§Ã£o de cÃ³digo:** O `.proto` gera automaticamente classes em Python, Java, Go, etc. O cliente chama mÃ©todos como se fossem funÃ§Ãµes locais.

**Porta padrÃ£o:** `50051` (por convenÃ§Ã£o, nÃ£o obrigatÃ³rio).

**4 tipos de comunicaÃ§Ã£o gRPC:**

| Tipo | DescriÃ§Ã£o | Caso de uso |
|:-----|:----------|:------------|
| **Unary** | 1 request â†’ 1 response | Consulta pontual (como REST) |
| **Server Streaming** | 1 request â†’ N responses | Stream de mÃ©tricas |
| **Client Streaming** | N requests â†’ 1 response | Upload de batch de dados |
| **Bidirectional Streaming** | N requests â†” N responses | Chat em tempo real |

### Apache Thrift

Similar ao gRPC em conceito, mas nasceu no Facebook:
*   Usa uma **IDL (Interface Definition Language)** prÃ³pria (arquivo `.thrift`) para definir contratos, assim como o gRPC usa `.proto`.
*   Suporta mÃºltiplos transportes (TCP, HTTP) e protocolos de serializaÃ§Ã£o (binÃ¡rio compacto, JSON).
*   **Porta padrÃ£o:** `9090`
*   **Onde vocÃª encontra:** Hive Metastore (`9083`), Impala, sistemas Hadoop legados.

```thrift
// metastore.thrift â€” exemplo simplificado do Hive Metastore
service ThriftHiveMetastore {
    Table get_table(1: string dbname, 2: string tbl_name)
    list<string> get_all_databases()
    void create_table(1: Table tbl)
}
```

> **Na prÃ¡tica:** Quando seu Spark conecta ao Hive Metastore na porta 9083, ele estÃ¡ falando **Thrift binÃ¡rio**, nÃ£o HTTP. Ã‰ por isso que vocÃª nÃ£o consegue "cURL" o Metastore â€” Ã© protocolo binÃ¡rio.

---

## 2. Comparativo: REST vs gRPC vs GraphQL

TrÃªs paradigmas de API que vocÃª encontra no mundo real:

| Aspecto | REST (HTTP/JSON) | gRPC (HTTP/2/Protobuf) | GraphQL (HTTP/JSON) |
|:--------|:-----------------|:-----------------------|:--------------------|
| **Formato** | JSON (texto) | Protobuf (binÃ¡rio) | JSON (texto) |
| **Transporte** | HTTP/1.1 ou 2 | HTTP/2 obrigatÃ³rio | HTTP/1.1 ou 2 |
| **Contrato** | OpenAPI/Swagger (opcional) | `.proto` (obrigatÃ³rio) | Schema (obrigatÃ³rio) |
| **Tipagem** | Fraca (JSON nÃ£o tem tipos) | Forte (Protobuf tipado) | Forte (schema tipado) |
| **Streaming** | NÃ£o nativo (SSE Ã© workaround) | Nativo (4 tipos) | Subscriptions (via WebSocket) |
| **Performance** | Boa para humanos, ok para mÃ¡quinas | Excelente (10x+ menor/rÃ¡pido) | Boa, reduz over-fetching |
| **Debugging** | FÃ¡cil (curl, browser) | DifÃ­cil (precisa ferramentas especiais) | MÃ©dio (playground visual) |
| **Caso de uso** | APIs pÃºblicas, CRUD, integraÃ§Ã£o | MicroserviÃ§os internos, alto volume | Frontend flexÃ­vel, mÃºltiplos clientes |

### Quando usar o quÃª?

```
Seus dados precisam de...

  Alta performance + Volume massivo?
    â””â”€â”€ gRPC (Protobuf)
        Ex: comunicaÃ§Ã£o entre microserviÃ§os, streaming de mÃ©tricas

  Flexibilidade de consulta + MÃºltiplos frontends?
    â””â”€â”€ GraphQL
        Ex: dashboard que precisa de dados diferentes dependendo da tela

  Simplicidade + APIs pÃºblicas + Debugging fÃ¡cil?
    â””â”€â”€ REST (HTTP/JSON)
        Ex: APIs pÃºblicas, webhooks, integraÃ§Ã£o com parceiros

  Ecossistema Hadoop legado?
    â””â”€â”€ Thrift
        Ex: Hive Metastore, Impala
```

---

## 3. O que estÃ¡ Acontecendo por Baixo dos Panos

### 3.1 Quando o Spark lÃª do S3

Engenheiros de dados usam `spark.read.parquet("s3://bucket/tabela/")` como se fosse mÃ¡gica. Mas por baixo do pano, Ã© HTTP puro.

**O que acontece:**
```
spark.read.parquet("s3://meu-bucket/vendas/")

1.  HEAD s3://meu-bucket/vendas/
    â†’ Spark usa HEAD para listar os arquivos e ver seus tamanhos

2.  GET s3://meu-bucket/vendas/part-00001.parquet
    Range: bytes=0-65535
    â†’ Spark lÃª o "footer" do Parquet (metadados: schema, row groups)

3.  GET s3://meu-bucket/vendas/part-00001.parquet
    Range: bytes=1048576-2097152
    â†’ Spark lÃª apenas as colunas que vocÃª precisa (column pruning!)
    â†’ Cada executor faz requests em paralelo para diferentes parts

4.  Cada executor â†’ TCP connection â†’ HTTPS (TLS) â†’ S3 API (REST)
```

**Pontos-chave:**
*   Spark usa **HTTP REST** (nÃ£o SDK binÃ¡rio) para falar com S3.
*   `Range` headers permitem ler pedaÃ§os do arquivo (crucial para Parquet column pruning).
*   Cada executor abre suas prÃ³prias conexÃµes HTTP â€” Ã© por isso que paralelismo funciona.
*   Se vocÃª vÃª `SlowDown` (429) nos logs, o S3 estÃ¡ fazendo rate limiting nas suas requests.

### 3.2 O Fluxo Completo: Backend â†’ Frontend

Quando um usuÃ¡rio acessa um dashboard de dados moderno:

```
Browser (Frontend React)
    â”‚
    â”‚â”€â”€ 1. GET /index.html â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ CDN/Nginx (Arquivos EstÃ¡ticos)
    â”‚â—€â”€â”€ HTML + JS + CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚
    â”‚â”€â”€ 2. GET /api/metricas â”€â”€â”€â”€â”€â”€â”€â”€â†’ Load Balancer (:443)
    â”‚                                       â”‚
    â”‚                                       â–¼
    â”‚                                   FastAPI (:8000)
    â”‚                                       â”‚
    â”‚                                       â”œâ”€â”€ SELECT * FROM metricas
    â”‚                                       â”‚   â†’ PostgreSQL (:5432) [Wire Protocol]
    â”‚                                       â”‚
    â”‚                                       â”œâ”€â”€ Cache check
    â”‚                                       â”‚   â†’ Redis (:6379) [RESP Protocol]
    â”‚                                       â”‚
    â”‚                                       â””â”€â”€ Busca semÃ¢ntica
    â”‚                                           â†’ Milvus (:19530) [gRPC]
    â”‚                                       
    â”‚â—€â”€â”€ 200 OK {json} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚
    â”‚â”€â”€ 3. SSE /api/stream/updates â”€â”€â†’ FastAPI (conexÃ£o mantida aberta)
    â”‚â—€â”€â”€ data: {"cpu": 45.2}\n\n â”€â”€â”€â”‚  (server pushes a cada 1s)
    â”‚â—€â”€â”€ data: {"cpu": 47.1}\n\n â”€â”€â”€â”‚
    â”‚â—€â”€â”€ data: {"cpu": 44.8}\n\n â”€â”€â”€â”‚
```

**O que estÃ¡ acontecendo em cada nÃ­vel:**
1.  **CDN/Nginx** serve arquivos estÃ¡ticos (HTML, JS, imagens) â€” payload grande mas cacheÃ¡vel.
2.  **REST API** serve dados dinÃ¢micos (mÃ©tricas, consultas) â€” JSON sobre HTTP.
3.  **SSE** mantÃ©m uma conexÃ£o HTTP aberta para updates em tempo real â€” o servidor "empurra" dados.

### 3.3 SerializaÃ§Ã£o: Protobuf vs JSON vs Avro

A escolha do formato de serializaÃ§Ã£o impacta diretamente performance e interoperabilidade:

| Aspecto | JSON | Protobuf | Avro |
|:--------|:-----|:---------|:-----|
| **Formato** | Texto | BinÃ¡rio | BinÃ¡rio |
| **Schema** | ImplÃ­cito | `.proto` (IDL) | `.avsc` (JSON Schema) |
| **EvoluÃ§Ã£o de Schema** | FrÃ¡gil (sem regras) | Forward/backward compat | Forward/backward compat |
| **Tamanho** | Grande (verbose) | Muito pequeno | Pequeno |
| **Parse speed** | Lento | Muito rÃ¡pido | RÃ¡pido |
| **Human-readable** | Sim âœ… | NÃ£o âŒ | NÃ£o âŒ |
| **Ecossistema** | Universal | Google, gRPC | Hadoop, Kafka, Confluent |

**Quando usar:**

*   **JSON:** APIs pÃºblicas, configuraÃ§Ãµes, debugging, integraÃ§Ã£o com parceiros.
*   **Protobuf:** ComunicaÃ§Ã£o entre microserviÃ§os (gRPC), alta performance, baixa latÃªncia.
*   **Avro:** Kafka topics (schema registry), data lake (evoluÃ§Ã£o de schema Ã© crÃ­tica entre producer e consumer).

---

## 4. ComunicaÃ§Ã£o em Tempo Real: SSE e WebSocket

### SSE (Server-Sent Events): O Servidor "Empurra"

SSE Ã© uma tecnologia **unidirecional**: o servidor envia dados para o cliente continuamente, mas o cliente nÃ£o envia dados de volta (sÃ³ o request inicial).

**Como funciona:**

```
Cliente: GET /stream HTTP/1.1
         Accept: text/event-stream

Servidor: HTTP/1.1 200 OK
          Content-Type: text/event-stream
          Cache-Control: no-cache
          Connection: keep-alive

          data: {"metrica": "cpu", "valor": 45.2}

          data: {"metrica": "cpu", "valor": 47.1}

          event: alerta
          data: {"msg": "CPU acima de 90%!"}

          (conexÃ£o fica aberta indefinidamente...)
```

**Detalhes tÃ©cnicos (da MDN):**

*   O Content-Type Ã© `text/event-stream`.
*   Cada mensagem termina com `\n\n` (duas newlines).
*   O campo `event:` define tipos customizados de eventos.
*   Se a conexÃ£o cai, o browser **reconecta automaticamente** (comportamento padrÃ£o do `EventSource`).
*   Um server pode enviar comentÃ¡rios (linhas comeÃ§ando com `:`) como heartbeat para manter a conexÃ£o viva.

**Em Python (servidor):**

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import asyncio, json

app = FastAPI()

async def gerar_metricas():
    while True:
        dados = {"cpu": random.uniform(10, 90), "ts": time.time()}
        yield f"data: {json.dumps(dados)}\n\n"
        await asyncio.sleep(1)

@app.get("/stream/metricas")
async def stream():
    return StreamingResponse(
        gerar_metricas(),
        media_type="text/event-stream"
    )
```

### WebSocket: ComunicaÃ§Ã£o Bidirecional

Enquanto SSE Ã© unidirecional (servidor â†’ cliente), **WebSocket** Ã© bidirecional â€” ambos os lados podem enviar dados a qualquer momento.

**Como funciona:**

```
1. O cliente faz um HTTP request especial (Upgrade):
   GET /chat HTTP/1.1
   Upgrade: websocket
   Connection: Upgrade

2. O servidor aceita:
   HTTP/1.1 101 Switching Protocols
   Upgrade: websocket

3. A partir daqui, NÃƒO Ã‰ MAIS HTTP.
   A conexÃ£o TCP Ã© "promovida" para o protocolo WebSocket.
   Ambos os lados enviam mensagens livremente:
   
   Cliente: {"msg": "OlÃ¡!"}
   Servidor: {"msg": "Oi, como posso ajudar?"}
   Cliente: {"msg": "Preciso dos dados de vendas"}
   Servidor: {"vendas": [...], "total": 1523}
```

### SSE vs WebSocket: Quando usar o quÃª?

| Aspecto | SSE | WebSocket |
|:--------|:----|:----------|
| **DireÃ§Ã£o** | Servidor â†’ Cliente (unidirecional) | Bidirecional |
| **Protocolo** | HTTP padrÃ£o | Protocolo prÃ³prio (ws://) |
| **ReconexÃ£o automÃ¡tica** | Sim (built-in) | NÃ£o (precisa implementar) |
| **Compatibilidade** | Funciona com proxies HTTP | Pode ter problemas com proxies legados |
| **Caso de uso** | Dashboards, feeds, notificaÃ§Ãµes, **LLM token streaming** | Chat, jogos, ediÃ§Ã£o colaborativa |
| **Complexidade** | Simples | Mais complexo |

> **Para DE:** SSE Ã© o que vocÃª mais encontra. LLMs (ChatGPT, Claude) usam SSE para enviar tokens um a um enquanto geram a resposta. Se vocÃª precisar consumir uma API de LLM com streaming, Ã© SSE.

---

## 5. Portas e Protocolos Modernos: IA e Busca Vetorial

A nova geraÃ§Ã£o de ferramentas de dados e IA usa portas altas e protocolos especÃ­ficos:

| ServiÃ§o | Porta | Protocolo | O que faz |
|:--------|:------|:----------|:----------|
| **Milvus** | 19530 (gRPC), 9091 (mÃ©tricas) | gRPC + REST | Banco vetorial para similarity search |
| **Qdrant** | 6333 (REST), 6334 (gRPC) | REST + gRPC | Banco vetorial alternativo |
| **ChromaDB** | 8000 | REST | Banco vetorial leve |
| **Ollama** | 11434 | REST | LLM local (Llama, Mistral) |
| **LangServe** | 8000 | REST + SSE | APIs de LLM com LangChain |
| **MLflow** | 5000 | REST | Tracking de experimentos ML |

### A LÃ³gica por trÃ¡s das portas altas

Todas essas ferramentas usam portas no range **User Ports (1024-49151)**. Por quÃª?

1.  **NÃ£o precisam de root**: portas acima de 1024 podem ser abertas por qualquer usuÃ¡rio.
2.  **Evitam conflito**: portas baixas jÃ¡ estÃ£o "ocupadas" por serviÃ§os clÃ¡ssicos.
3.  **ConvenÃ§Ã£o > necessidade**: o nÃºmero em si nÃ£o importa tecnicamente. Ã‰ uma convenÃ§Ã£o para que a comunidade reconheÃ§a o serviÃ§o.

### Como Embeddings e Busca Vetorial se encaixam

O fluxo de uma busca semÃ¢ntica usando Vector DB:

```
1. Texto "Como fazer ETL com Spark?"
        â”‚
        â–¼
2. Modelo de Embedding (ex: OpenAI text-embedding-ada-002)
   â†’ Transforma texto em vetor: [0.023, -0.451, 0.128, ..., 0.067]
   â†’ DimensÃ£o: 1536 floats
        â”‚
        â–¼
3. Busca no Milvus (gRPC :19530)
   â†’ "Encontre os 10 vetores mais similares a este"
   â†’ Usa distÃ¢ncia coseno/euclidiana
        â”‚
        â–¼
4. Resultados: documentos semanticamente prÃ³ximos
   â†’ Score: 0.95, 0.91, 0.87...
   â†’ IDs dos documentos originais
```

*   O embedding model roda via **REST API** (HTTP/JSON para OpenAI, ou HTTP local para Ollama).
*   A busca vetorial roda via **gRPC** (mais rÃ¡pido para alta frequÃªncia) ou **REST** (mais simples para protÃ³tipos).

---

## ğŸ’¡ Nota de RodapÃ©: A LÃ³gica por trÃ¡s dos NÃºmeros de Porta (Resumo)

```
Porta Baixa (0-1023):
  â†’ ServiÃ§os "clÃ¡ssicos" da internet (HTTP, SSH, DNS)
  â†’ Exigem root
  â†’ NÃºmero definido na "era dourada" (anos 70-90)

Porta MÃ©dia (1024-49151):
  â†’ Bancos de dados, ferramentas modernas
  â†’ Qualquer usuÃ¡rio pode abrir
  â†’ Registradas na IANA por convenÃ§Ã£o

Porta Alta (49152-65535):
  â†’ EfÃªmeras (temporÃ¡rias)
  â†’ O OS escolhe para conexÃµes de saÃ­da
  â†’ VocÃª raramente configura diretamente
```

---

## ğŸ§  Checkpoint: Teste seu Entendimento

1.  **Por que o Spark lÃª do S3 usando HTTP REST e nÃ£o um protocolo binÃ¡rio mais rÃ¡pido?** Qual a vantagem dessa decisÃ£o de design?
2.  **Seu Hive Metastore estÃ¡ na porta 9083. VocÃª tenta `curl localhost:9083` e recebe lixo binÃ¡rio. Por quÃª?** Qual protocolo o Metastore usa?
3.  **Uma API de LLM envia tokens um a um usando SSE. Por que SSE e nÃ£o WebSocket?** O LLM precisa receber dados do cliente durante a geraÃ§Ã£o?
4.  **VocÃª precisa escolher o formato de serializaÃ§Ã£o para um Kafka topic que terÃ¡ 500 producers e evoluÃ§Ã£o de schema frequente. JSON, Protobuf ou Avro?** Por quÃª?

<details>
<summary><strong>Respostas</strong></summary>

1. A API do S3 Ã© uma **API REST HTTP** por design (compatÃ­vel com qualquer client HTTP). A vantagem Ã© **universalidade**: qualquer linguagem/ferramenta que fala HTTP consegue ler do S3. NÃ£o precisa de SDK especial. AlÃ©m disso, CDNs e caches HTTP funcionam nativamente. A performance Ã© compensada pelo paralelismo massivo (muitos executors fazendo requests simultÃ¢neos).

2. O Hive Metastore usa **Apache Thrift** (protocolo binÃ¡rio), nÃ£o HTTP. `curl` envia um request HTTP que o Metastore nÃ£o entende, e o Metastore responde em binÃ¡rio que o `curl` nÃ£o entende. Para interagir, vocÃª precisa de um Thrift client (`beeline`, `pyspark`, ou `hive` CLI).

3. SSE Ã© suficiente porque a geraÃ§Ã£o de texto Ã© **unidirecional**: o servidor envia tokens, o cliente apenas recebe. O prompt jÃ¡ foi enviado no request inicial (POST). WebSocket seria overkill â€” adiciona complexidade (protocolo diferente, reconexÃ£o manual) sem benefÃ­cio, jÃ¡ que o cliente nÃ£o precisa enviar dados durante a geraÃ§Ã£o.

4. **Avro**. RazÃµes: (a) Avro tem **evoluÃ§Ã£o de schema** nativa com forward/backward compatibility, essencial para 500 producers que podem estar em versÃµes diferentes. (b) O **Schema Registry** do Kafka (Confluent) Ã© construÃ­do para Avro. (c) Protobuf tambÃ©m suporta evoluÃ§Ã£o de schema, mas o ecossistema Kafka Ã© mais maduro com Avro. JSON nÃ£o tem garantias de schema.

</details>

---

## ğŸ¯ AplicaÃ§Ã£o Imediata

**ExercÃ­cio: Consumindo SSE com Python (5 min)**

```python
# Usando httpx para consumir um stream SSE
# Instale: pip install httpx

import httpx

# SSE pÃºblico de teste (stream de nÃºmeros aleatÃ³rios):
url = "https://sse.dev/test"

# httpx suporta streaming nativamente:
with httpx.stream("GET", url, timeout=None) as response:
    print(f"Status: {response.status_code}")
    print(f"Content-Type: {response.headers.get('content-type')}")
    print("---")
    count = 0
    for line in response.iter_lines():
        if line.startswith("data:"):
            dados = line[5:].strip()
            print(f"Evento {count}: {dados}")
            count += 1
            if count >= 5:
                break  # Para depois de 5 eventos

print(f"\nRecebidos {count} eventos via SSE!")
```

**Alternativa com curl:**

```bash
# Ver SSE no terminal (Ctrl+C para parar):
curl -N https://sse.dev/test
# -N desabilita buffering, mostrando cada evento em tempo real
```

---

## ğŸ”— ConexÃµes com outras aulas deste mÃ³dulo

| Aula | Como se conecta |
|:-----|:----------------|
| [01 - Internet Fundamentals](../01_internet_fundamentals.md) | gRPC e Thrift rodam sobre TCP/IP. Os conceitos de pacotes e transporte se aplicam aqui. |
| [02 - Network Ports](../02_network_ports.md) | Portas altas (50051, 19530, 6379) sÃ£o User Ports. O conceito de faixas e IANA explica por quÃª. |
| [03 - Internet Security](../03_internet_security.md) | gRPC em produÃ§Ã£o usa TLS. SSE via HTTPS Ã© SSE sobre TLS. |
| [04 - HTTP](../04_http.md) | gRPC usa HTTP/2. SSE usa HTTP com conexÃ£o mantida. REST Ã© HTTP + JSON. Tudo conecta aqui. |
