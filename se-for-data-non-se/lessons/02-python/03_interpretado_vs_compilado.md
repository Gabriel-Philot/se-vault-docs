# Mini-Aula 02.3: Python vs C â€” Interpretado vs Compilado

> **Objetivo:** Entender como linguagens executam cÃ³digo e por que isso importa para Data Engineering.

---

## 1. O que Ã© CompilaÃ§Ã£o? (C como exemplo)

**CompilaÃ§Ã£o:** transformar cÃ³digo-fonte inteiro em cÃ³digo de mÃ¡quina **antes** da execuÃ§Ã£o.

```
CÃ³digo (.c) â†’ Preprocessor â†’ Compiler â†’ Assembler â†’ Linker â†’ ExecutÃ¡vel nativo
```

### As 4 Etapas

| Etapa | O que faz | Output |
|-------|-----------|--------|
| **Preprocessing** | Expande `#include`, `#define`, remove comentÃ¡rios | CÃ³digo expandido |
| **Compilation** | Traduz para assembly (especÃ­fico da CPU) | Arquivo `.s` |
| **Assembly** | Converte assembly em object code | Arquivo `.o` |
| **Linking** | Junta object files + bibliotecas | ExecutÃ¡vel binÃ¡rio |

**Resultado:** binÃ¡rio que roda **direto na CPU**, sem intermediÃ¡rios.

```c
// hello.c
#include <stdio.h>
int main() {
    printf("Hello, World!\n");
    return 0;
}
```
```bash
gcc hello.c -o hello    # compila
./hello                  # executa binÃ¡rio nativo
```

---

## 2. O que Ã© InterpretaÃ§Ã£o? (Python)

Python usa modelo **hÃ­brido**: compila para bytecode, depois interpreta.

```
CÃ³digo (.py) â†’ CPython compila â†’ Bytecode (.pyc) â†’ PVM interpreta â†’ CPU
```

### O Processo

1. **CompilaÃ§Ã£o para Bytecode**
   - CÃ³digo-fonte â†’ bytecode (`.pyc` em `__pycache__/`)
   - Bytecode Ã© **independente de plataforma**
   - Acontece automaticamente ao rodar

2. **Python Virtual Machine (PVM)**
   - LÃª e executa bytecode instruÃ§Ã£o por instruÃ§Ã£o
   - Gerencia memÃ³ria, tipos, exceÃ§Ãµes em runtime

```python
# hello.py
print("Hello, World!")  # executa direto, sem compilaÃ§Ã£o manual
```

> **Por que ainda Ã© "interpretado"?** O executÃ¡vel final (bytecode) ainda precisa de um intÃ©rprete (PVM) para rodar. NÃ£o Ã© cÃ³digo de mÃ¡quina nativo.

---

## 3. Tabela Comparativa: C vs Python

| Aspecto | C | Python |
|---------|---|--------|
| **Modelo de execuÃ§Ã£o** | Compilado â†’ binÃ¡rio nativo | Bytecode â†’ PVM interpreta |
| **Tipagem** | EstÃ¡tica (compile-time) | DinÃ¢mica (runtime) |
| **Portabilidade** | Recompilar por plataforma | Mesmo `.pyc` roda em qualquer OS |
| **Velocidade** | Muito rÃ¡pida | 10-200Ã— mais lenta |
| **MemÃ³ria** | Manual (`malloc`/`free`) | AutomÃ¡tica (GC) |
| **Sintaxe** | Verbosa, explÃ­cita | Concisa, legÃ­vel |
| **Ponteiros** | Sim, explÃ­citos | NÃ£o (usa referÃªncias) |
| **OOP** | NÃ£o nativo (struct-based) | Classes built-in |
| **Biblioteca padrÃ£o** | MÃ­nima | Extensa ("batteries included") |
| **Tratamento de erros** | Return codes, checks manuais | Exceptions |

### Entendendo as DiferenÃ§as

- **Tipagem estÃ¡tica vs dinÃ¢mica:** Em C, `int x = 5;` Ã© fixo â€” x sempre serÃ¡ int. Em Python, `x = 5` depois `x = "texto"` funciona (duck typing). Isso dÃ¡ flexibilidade, mas custa performance (checagem em runtime).
- **Ponteiros vs referÃªncias:** C expÃµe endereÃ§os de memÃ³ria diretamente. Python abstrai isso â€” vocÃª manipula referÃªncias, nÃ£o endereÃ§os.
- **Biblioteca padrÃ£o:** C tem sÃ³ o bÃ¡sico (I/O, strings, math). Python vem com JSON, HTTP, regex, datetime, etc. prontinhos.
- **Tratamento de erros:** Em C vocÃª checa `if (result == -1)`. Python usa `try/except` â€” mais legÃ­vel, mas com overhead.

### Benchmark Real

| Tarefa | C | Python | DiferenÃ§a |
|--------|---|--------|-----------|
| Loop atÃ© 1 bilhÃ£o | 21ms | 79,000ms | **3,761Ã— mais lenta** |
| Contar primos atÃ© 250k | 0.012s | 0.261s | **21Ã— mais lenta** |
| Fibonacci recursivo | ~1x | ~40x | **40Ã— mais lenta** |

---

## 4. Por que isso Importa para Dados?

### 4.1 Performance de Loops

Python puro Ã© **muito lento** para loops intensivos:

```python
# âŒ LENTO: loop Python puro
total = 0
for i in range(1_000_000):
    total += i * i

# âœ… RÃPIDO: NumPy (C por baixo dos panos)
import numpy as np
arr = np.arange(1_000_000)
total = np.sum(arr ** 2)  # 100x mais rÃ¡pido
```

**LiÃ§Ã£o:** Em Data Engineering, **evite loops Python puros**. Use bibliotecas vetorizadas.

### 4.2 GIL e Threading

O **Global Interpreter Lock (GIL)** do CPython:
- Permite apenas **1 thread executar Python por vez**
- Impede paralelismo real em CPU-bound tasks
- Threads funcionam para I/O (aguardar rede, disco)

```python
# CPU-bound: threads NÃƒO ajudam (GIL bloqueia)
# Use multiprocessing para paralelismo real

from multiprocessing import Pool

def processar(chunk):
    return sum(x**2 for x in chunk)

with Pool(4) as p:  # 4 processos separados (sem GIL)
    resultados = p.map(processar, chunks)
```

> **ğŸ”® Python 3.13+ Free-Threaded (PEP 703)**
> 
> A partir do Python 3.13, existe um build **experimental sem GIL** (`--disable-gil`).
> 
> **Benchmarks reais:**
> - Multi-threaded CPU-bound: **~80% mais rÃ¡pido** (8.5s â†’ 1.5s)
> - Fibonacci com 8 threads: **84% mais rÃ¡pido**
> - Escalabilidade quase linear com nÃºmero de cores
> 
> **Trade-off:** Single-threaded fica ~40% mais lento (projetado cair para ~10% no 3.14).
> 
> **Status:** Experimental atÃ© ~2030 para manter compatibilidade com extensÃµes C.

### 4.3 Por que Spark usa JVM?

**Problema:** Python Ã© lento demais para processar terabytes.

**SoluÃ§Ã£o do Spark:**
1. **Core em Scala/Java** â†’ roda na JVM, compilado para bytecode JVM
2. **JVM tem JIT** â†’ compila hot paths para cÃ³digo nativo em runtime
3. **PySpark** â†’ API Python, mas execuÃ§Ã£o em JVM

```
PySpark Code â†’ Driver Python â†’ Serializa para JVM â†’ Workers JVM executam
```

**Trade-off:** VocÃª escreve Python (produtividade), mas o trabalho pesado roda em JVM (performance).

| Framework | Linguagem Core | Por quÃª? |
|-----------|----------------|----------|
| **Spark** | Scala (JVM) | JIT, garbage collection madura |
| **Pandas** | C/Cython | OperaÃ§Ãµes vetorizadas nativas |
| **Polars** | Rust | SeguranÃ§a + performance nativa |
| **DuckDB** | C++ | SQL engine otimizada |

---

## 5. Resumo PrÃ¡tico

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  C (Compilado)              Python (Interpretado)          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
â”‚  CÃ³digo â†’ BinÃ¡rio nativo    CÃ³digo â†’ Bytecode â†’ PVM        â”‚
â”‚  MÃ¡xima performance         Flexibilidade/produtividade    â”‚
â”‚  Controle total memÃ³ria     GC automÃ¡tico                  â”‚
â”‚  Portabilidade: recompilar  Mesmo cÃ³digo roda em tudo      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Para Data Engineers:**
1. **Loops:** use NumPy/Pandas (C por baixo), nÃ£o Python puro
2. **Paralelismo:** `multiprocessing` para CPU, `threading` para I/O
3. **Big Data:** engines JVM (Spark) ou nativas (Polars/DuckDB)
4. **Entenda o trade-off:** Python = produtividade, delegate performance para bibliotecas

---

## ConexÃµes

- **Anterior:** [02 - Linux, Processos e Bash](./02_linux_so_bash.md)
- **PrÃ³ximo:** [04 - Stack vs Heap](./04_stack_vs_heap.md)
- **Complementar:** Por que frameworks modernos (Polars, DuckDB) escolhem Rust/C++
